#!/usr/bin/env python3
"""
Demo Script - ×“×•×’×× ××¢×©×™×ª ×œ×©×™××•×© ×‘××—×œ×§×ª Enhanced TelemetryGeneratorPro

×©×™××•×©:
    python demo_script.py
    
××” ×”×¡×§×¨×™×¤×˜ ×¢×•×©×”:
1. ×™×•×¦×¨ ×§×•×‘×¥ schema.json ×œ×“×•×’××
2. ×˜×•×¢×Ÿ ××•×ª×• ×‘××—×œ×§×”
3. ×™×•×¦×¨ ×§×‘×¦×™× ×‘×™× ××¨×™×™×
4. ××¦×™×’ ×¡×˜×˜×™×¡×˜×™×§×•×ª
"""

import os
import json
import time
from pathlib import Path

# ×™×™×‘×•× ×”××—×œ×§×•×ª ×©×œ× ×•
from generator import (
    EnhancedTelemetryGeneratorPro,
    RecordType,
    OutputFormat
)

def create_demo_schema():
    """×™×•×¦×¨ schema ×œ×“×•×’×× ×¢× ××’×•×•×Ÿ ×¡×•×’×™ ×©×“×•×ª"""
    schema = {
        # Float fields
        "cpu_temperature": {
            "type": "float", 
            "bits": 32, 
            "min": 30.0, 
            "max": 90.0,
            "encoding": "ieee754"
        },
        "voltage": {
            "type": "float", 
            "bits": 32, 
            "min": 11.5, 
            "max": 12.5
        },
        
        # Integer fields
        "cpu_usage": {"type": "int", "bits": 8},  # 0-255
        "memory_usage": {"type": "int", "bits": 8},  # 0-255
        "fan_speed": {"type": "int", "bits": 12},  # 0-4095 RPM
        
        # String fields
        "hostname": {
            "type": "string", 
            "length": 12, 
            "compressed": True,
            "char_bits": 6
        },
        "device_id": {
            "type": "string", 
            "length": 8, 
            "max_length": 16
        },
        
        # Boolean field
        "is_online": {"type": "bool"},
        
        # String enums
        "system_status": {
            "type": "enum", 
            "values": ["healthy", "warning", "critical", "maintenance", "offline"]
        },
        "alert_level": {
            "type": "enum", 
            "values": ["none", "low", "medium", "high"]
        },
        
        # Integer enum
        "error_code": {
            "type": "enum", 
            "values": [0, 100, 200, 404, 500, 503]
        },
        
        # Time field
        "uptime_seconds": {
            "type": "time", 
            "bits": 32, 
            "range": 604800  # 1 week in seconds
        }
    }
    
    return schema

def main():
    print("=== Enhanced TelemetryGeneratorPro Demo ===")
    print("×™×•×¦×¨ × ×ª×•× ×™ ×˜×œ××˜×¨×™×” ××–×•×™×™×¤×™× ×œ×“×™××•×™ ×¢×•××¡\n")
    
    # ×™×¦×™×¨×ª ×ª×™×§×™×•×ª
    output_dir = Path("./demo_output")
    output_dir.mkdir(exist_ok=True)
    
    schema_file = "demo_schema.json"
    
    try:
        # ×©×œ×‘ 1: ×™×¦×™×¨×ª Schema
        print("ğŸ“„ ×™×•×¦×¨ ×§×•×‘×¥ schema...")
        demo_schema = create_demo_schema()
        
        with open(schema_file, 'w', encoding='utf-8') as f:
            json.dump(demo_schema, f, indent=2, ensure_ascii=False)
        
        print(f"   âœ“ × ×•×¦×¨: {schema_file}")
        print(f"   ğŸ“Š {len(demo_schema)} ×©×“×•×ª ×‘×¡×›××”")
        
        # ×©×œ×‘ 2: ×˜×¢×™× ×ª ×”××—×œ×§×”
        print("\nğŸ”§ ×˜×•×¢×Ÿ schema ×•×™×•×¦×¨ ××—×•×œ×œ...")
        generator = EnhancedTelemetryGeneratorPro(
            schema_file=schema_file,
            output_dir=str(output_dir),
            add_sequential_id=True,
            enable_gpu=False  # ×œ×“×•×’×× ×œ×œ× GPU
        )
        
        # ×”×¦×’×ª ××™×“×¢ ×¢×œ ×”×¡×›××”
        info = generator.get_enhanced_schema_info()
        print(f"   âœ“ × ×˜×¢×Ÿ ×‘×”×¦×œ×—×”")
        print(f"   ğŸ“ {info['data_fields_count']} ×©×“×•×ª × ×ª×•× ×™×")
        print(f"   ğŸ’¾ {info['bytes_per_record']} bytes ×œ×¨×©×•××”")
        print(f"   ğŸ”§ {info['overhead_bits']} bits overhead")
        
        # ×©×œ×‘ 3: ×™×¦×™×¨×ª ×§×•×‘×¥ ×‘×™× ××¨×™ ×™×—×™×“
        print("\nâš¡ ×™×•×¦×¨ ×§×•×‘×¥ ×‘×™× ××¨×™ ×™×—×™×“...")
        single_file = output_dir / "telemetry_single.bin"
        
        start_time = time.time()
        generator.write_records_enhanced(
            str(single_file),
            10000,  # 10K records
            output_format=OutputFormat.BINARY,
            record_type_ratio={
                RecordType.UPDATE: 0.8,  # 80% updates
                RecordType.EVENT: 0.2    # 20% events
            }
        )
        elapsed = time.time() - start_time
        
        file_size = single_file.stat().st_size
        print(f"   âœ“ × ×•×¦×¨: {single_file.name}")
        print(f"   ğŸ“Š 10,000 records ×‘-{elapsed:.2f} ×©× ×™×•×ª")
        print(f"   ğŸ’¾ ×’×•×“×œ: {file_size:,} bytes ({file_size/1024/1024:.2f} MB)")
        print(f"   âš¡ ××”×™×¨×•×ª: {10000/elapsed:,.0f} records/sec")
        
        # ×©×œ×‘ 4: ×™×¦×™×¨×ª ×§×‘×¦×™× ××¨×•×‘×™× ×‘××§×‘×™×œ
        print("\nğŸš€ ×™×•×¦×¨ ×§×‘×¦×™× ××¨×•×‘×™× ×‘××§×‘×™×œ...")
        
        start_time = time.time()
        binary_paths = generator.generate_multiple_files_enhanced(
            num_files=5,
            records_per_file=20000,  # 100K total records
            file_prefix="telemetry_parallel",
            output_format=OutputFormat.BINARY,
            max_workers=4,
            record_type_ratio={
                RecordType.UPDATE: 0.7,
                RecordType.EVENT: 0.3
            }
        )
        elapsed = time.time() - start_time
        
        total_size = sum(Path(p).stat().st_size for p in binary_paths)
        total_records = 5 * 20000
        
        print(f"   âœ“ × ×•×¦×¨×• {len(binary_paths)} ×§×‘×¦×™×")
        print(f"   ğŸ“Š {total_records:,} records ×‘-{elapsed:.2f} ×©× ×™×•×ª")
        print(f"   ğŸ’¾ ×¡×”\"×› ×’×•×“×œ: {total_size:,} bytes ({total_size/1024/1024:.2f} MB)")
        print(f"   âš¡ ××”×™×¨×•×ª: {total_records/elapsed:,.0f} records/sec")
        
        # ×©×œ×‘ 5: ×™×¦×™×¨×ª ×§×•×‘×¥ JSON ×œ×“×™×‘×•×’×™× ×’
        print("\nğŸ› ×™×•×¦×¨ ×§×•×‘×¥ JSON ×œ×“×™×‘×•×’×™× ×’...")
        
        json_file = output_dir / "telemetry_debug.json"
        generator.write_records_enhanced(
            str(json_file),
            100,  # ×¨×§ 100 records ×œ×“×™×‘×•×’×™× ×’
            output_format=OutputFormat.JSON
        )
        
        print(f"   âœ“ × ×•×¦×¨: {json_file.name}")
        
        # ×”×¦×’×ª ×“×•×’×× ××”×§×•×‘×¥
        with open(json_file, 'r', encoding='utf-8') as f:
            first_record = json.loads(f.readline())
            sample_data = first_record['data']
            
        print("   ğŸ“„ ×“×•×’×× ××”× ×ª×•× ×™×:")
        print(f"      ğŸŒ¡ï¸ ×˜××¤×¨×˜×•×¨×”: {sample_data['cpu_temperature']:.1f}Â°C")
        print(f"      ğŸ’» ×©×™××•×© CPU: {sample_data['cpu_usage']}%")
        print(f"      ğŸ–¥ï¸ ×©× ×××¨×—: {sample_data['hostname']}")
        print(f"      âš ï¸ ×¨××ª ×”×ª×¨××”: {sample_data['alert_level']}")
        print(f"      âœ… ××¦×‘ ××¢×¨×›×ª: {sample_data['system_status']}")
        
        # ×©×œ×‘ 6: ×™×¦×™×¨×ª ×§×•×‘×¥ InfluxDB
        print("\nğŸ“ˆ ×™×•×¦×¨ ×§×•×‘×¥ InfluxDB Line Protocol...")
        
        influx_file = output_dir / "telemetry_influxdb.txt"
        generator.write_records_enhanced(
            str(influx_file),
            1000,
            output_format=OutputFormat.INFLUX_LINE
        )
        
        print(f"   âœ“ × ×•×¦×¨: {influx_file.name}")
        print(f"   ğŸ’¡ ×œ×™×™×‘× ×œ-InfluxDB: influx write -b your-bucket -f {influx_file}")
        
        # ×”×¦×’×ª ×“×•×’×× ×-InfluxDB
        with open(influx_file, 'r') as f:
            sample_line = f.readline().strip()
        print(f"   ğŸ“„ ×“×•×’××: {sample_line[:80]}...")
        
        # ×©×œ×‘ 7: ×¡×™×›×•× ×•×¡×˜×˜×™×¡×˜×™×§×•×ª
        print("\nğŸ“Š ×¡×™×›×•× ×”×“××•:")
        
        all_files = list(output_dir.glob("*"))
        total_files = len(all_files)
        total_size_all = sum(f.stat().st_size for f in all_files if f.is_file())
        
        print(f"   ğŸ“ × ×•×¦×¨×• {total_files} ×§×‘×¦×™×")
        print(f"   ğŸ’¾ ×¡×”\"×›: {total_size_all:,} bytes ({total_size_all/1024/1024:.2f} MB)")
        print(f"   ğŸ“Š ×¡×”\"×› records: ~{total_records + 10000 + 100 + 1000:,}")
        
        # ×”×¢×¨×›×ª ×“×¨×™×©×•×ª ××—×¡×•×Ÿ
        estimation = generator.estimate_storage_requirements(
            1000000,  # 1M records
            OutputFormat.BINARY,
            compression_ratio=0.6
        )
        
        print(f"\nğŸ”® ×”×¢×¨×›×” ×œ-1M records:")
        print(f"   ğŸ’¾ ×‘×™× ××¨×™: {estimation['compressed_mb']:.1f} MB (×“×—×•×¡)")
        print(f"   âš¡ ×–××Ÿ ×¦×¤×•×™: ~{1000000/10000:.0f} ×©× ×™×•×ª")
        
        print(f"\nâœ… ×”×“××• ×”×•×©×œ× ×‘×”×¦×œ×—×”!")
        print(f"ğŸ“‚ ×›×œ ×”×§×‘×¦×™× ×‘: {output_dir.absolute()}")
        
    except Exception as e:
        print(f"\nâŒ ×©×’×™××”: {e}")
        raise
    
    finally:
        # × ×™×§×•×™ ×§×•×‘×¥ schema (××•×¤×¦×™×•× ×œ×™)
        if os.path.exists(schema_file):
            # ××œ ×ª××—×§ - ×©××•×¨ ×œ×©×™××•×© ×—×•×–×¨
            print(f"\nğŸ’¡ ×§×•×‘×¥ Schema × ×©××¨: {schema_file}")

if __name__ == "__main__":
    main()
